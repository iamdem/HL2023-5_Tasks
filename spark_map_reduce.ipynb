{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dM8Fv5BZU6eI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import expr, hour, count, max, col, length\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "4e2hiDrrV_sw",
    "outputId": "c6bb9851-8555-4361-81c0-8096a1306cda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-ST7QJ9Q:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Our First Spark Example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x201d921ebf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from typing import List\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark= SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"Our First Spark Example\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Avi6i0SvVFvj"
   },
   "outputs": [],
   "source": [
    "\n",
    "driver_feedback_categories_good = [\n",
    "    \"great service\",\n",
    "    \"nice car\",\n",
    "    \"wonderful companion\",\n",
    "    \"neat and tidy\",\n",
    "    \"expert navigation\",\n",
    "    \"recommend\",\n",
    "]\n",
    "driver_feedback_categories_bad = [\n",
    "    \"awful service\",\n",
    "    \"bad car\",\n",
    "    \"unpleasant companion\",\n",
    "    \"dirty\",\n",
    "    \"non-expert navigation\",\n",
    "    \"not recommend\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jIXqGc7tVHrS"
   },
   "outputs": [],
   "source": [
    "def top_k_drivers(df: DataFrame, k: int):\n",
    "    return (\n",
    "        df.where(df.driver_rate.isNotNull())\n",
    "        .orderBy(df.driver_rate, ascending=False)\n",
    "        .select(\"driver_id\", \"driver_rate\")\n",
    "        .limit(k)\n",
    "        .rdd.map(lambda row: {\"driver_id\": row[0], \"driver_rate\": row[1]})\n",
    "    )\n",
    "\n",
    "\n",
    "def top_k_clients(df: DataFrame, k: int):\n",
    "    return (\n",
    "        df.where(df.client_rate.isNotNull())\n",
    "        .orderBy(df.client_rate, ascending=False)\n",
    "        .select(\"client_id\", \"client_rate\")\n",
    "        .limit(100)\n",
    "        .rdd.map(lambda row: {\"client_id\": row[0], \"client_rate\": row[1]})\n",
    "    )\n",
    "\n",
    "\n",
    "def top_k_drivers_by_profit(df: DataFrame, k: int):\n",
    "    return (\n",
    "        df.withColumn('cost', df.cost.cast('int'))\n",
    "        .groupBy('driver_id')\n",
    "        .agg(sum(df.cost).alias(\"profit\"))\n",
    "        .orderBy(\"profit\", ascending=False)\n",
    "        .select(\"driver_id\", \"profit\")\n",
    "        .limit(k)\n",
    "        .rdd.map(lambda row: {\"driver_id\": row[0], \"profit\": row[1]})\n",
    "    )\n",
    "\n",
    "\n",
    "def worst_drivers(df: DataFrame):\n",
    "    return (\n",
    "        df.where(df.driver_rate < 3.5)\n",
    "        .orderBy(df.driver_rate, ascending=True)\n",
    "        .select(\"driver_id\", \"driver_rate\")\n",
    "        .limit(100)\n",
    "        .rdd.map(lambda row: {\"driver_id\": row[0], \"driver_rate\": row[1]})\n",
    "    )\n",
    "\n",
    "\n",
    "def top_10_longest_text_comment(df: DataFrame):\n",
    "    return (\n",
    "        df.orderBy(length(df.text_driver_feedback), ascending=False)\n",
    "        .select(\"driver_id\", \"driver_rate\", \"text_driver_feedback\")\n",
    "        .limit(10)\n",
    "        .rdd.map(\n",
    "            lambda row: {\n",
    "                \"driver_id\": row[0],\n",
    "                \"driver_rate\": row[1],\n",
    "                \"text_driver_feedback\": row[2],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def top_driver_feedback_category(df: DataFrame):\n",
    "    return (\n",
    "        df.where(reduce(lambda a, b: a|b, (df.category_driver_feedback.like(\"%\"+category+\"%\") for category in driver_feedback_categories_good)))\n",
    "        .groupBy('category_driver_feedback')\n",
    "        .count()\n",
    "        .orderBy('count', ascending=False)\n",
    "        .select('category_driver_feedback')\n",
    "        .limit(1)\n",
    "        .rdd.map( lambda row: {'category_driver_feedback': row[0]})\n",
    "    )\n",
    "\n",
    "\n",
    "def top_complaint_feedback_category(df: DataFrame):\n",
    "  return (\n",
    "        df.where(reduce(lambda a, b: a|b, (df.category_driver_feedback.like(\"%\"+category+\"%\") for category in driver_feedback_categories_bad)))\n",
    "        .groupBy('category_driver_feedback')\n",
    "        .count()\n",
    "        .orderBy('count', ascending=False)\n",
    "        .select('category_driver_feedback')\n",
    "        .limit(1)\n",
    "        .rdd.map( lambda row: {'category_driver_feedback': row[0]})\n",
    "    )\n",
    "\n",
    "\n",
    "def top_night_riders(df: DataFrame, k: int):\n",
    "    df = df.withColumn(\"hour\", hour(df.start_time))\n",
    "    df = df.withColumn(\n",
    "        \"daytime\", expr(\"case when hour > 0 and hour < 7 then 'night' else 'day' end\")\n",
    "    )\n",
    "    windowSpec_hour = Window.partitionBy(\"driver_id\", \"daytime\")\n",
    "    windowSpec = Window.partitionBy(\"driver_id\")\n",
    "    df_1 = df.withColumn(\"driver_rides\", count(df.client_id).over(windowSpec))\n",
    "    df_1 = df_1.withColumn(\"hour_rides\", count(df.client_id).over(windowSpec_hour))\n",
    "    df_1 = df_1.withColumn(\"pct_rides\", df_1.hour_rides / df_1.driver_rides)\n",
    "    return (\n",
    "        df_1.where(df_1.daytime == \"night\")\n",
    "        .orderBy(\"pct_rides\", ascending=False)\n",
    "        .dropDuplicates([\"driver_id\", \"hour_rides\"])\n",
    "        .select(\"driver_id\", \"hour_rides\", \"pct_rides\")\n",
    "        .limit(k)\n",
    "        .rdd.map(\n",
    "            lambda row: {\n",
    "                \"driver_id\": row[0],\n",
    "                \"night_rides\": row[1],\n",
    "                \"pct_rides\": row[2],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def densest_traffic_by_hour(df: DataFrame):\n",
    "    df = df.withColumn(\"hour\", hour(df.start_time))\n",
    "    return (\n",
    "        df.groupBy(df.hour)\n",
    "        .agg(count(df.driver_id).alias(\"count_rides\"))\n",
    "        .orderBy(\"count_rides\", ascending=False)\n",
    "        .select(\"hour\", \"count_rides\")\n",
    "        .limit(1)\n",
    "        .rdd.map(\n",
    "            lambda row: {\"hour\": f\"{row[0]}-{(row[0]+1)//24}\", \"count_rides\": row[1]}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LmE-oxbKdD6q"
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "         StructField('driver_id', IntegerType(), False),\n",
    "         StructField('client_id', IntegerType(), False),\n",
    "         StructField('start', StringType(), False),\n",
    "         StructField('start_latitude', DoubleType(), False),\n",
    "         StructField('start_longtitude', DoubleType(), False),\n",
    "         StructField('finish', StringType(), False),\n",
    "         StructField('finish_latitude', DoubleType(), False),\n",
    "         StructField('finish_longtitude', DoubleType(), False),\n",
    "         StructField('distance', DoubleType(), False),\n",
    "         StructField('road_time', DoubleType(), False),\n",
    "         StructField('start_time', TimestampType(), False),\n",
    "         StructField('finish_time', TimestampType(), False),\n",
    "         StructField('cost', DoubleType(), False),\n",
    "         StructField('driver_rate', StringType(), True),\n",
    "         StructField('category_driver_feedback', StringType(), True),\n",
    "         StructField('text_driver_feedback', StringType(), True),\n",
    "         StructField('client_rate', StringType(), True),\n",
    "         StructField('category_client_feedback', StringType(), True),\n",
    "         StructField('text_client_feedback', StringType(), True)\n",
    "     ])\n",
    "# pd_df = pd.read_csv('rides.csv')\n",
    "df = spark.read.option(\"header\", True).schema(schema).csv(\"rides_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "z8fdDzYecKaA",
    "outputId": "b26cefdd-5668-4b5d-f4b3-1d9f1038c1e1"
   },
   "outputs": [],
   "source": [
    "# df=spark.createDataFrame(pd_df[:-1], schema=schema)\n",
    "    #df = spark.read.csv(\"/content/drive/MyDrive/rides.csv\", header=True)\n",
    "    # top-100 drivers - variant 1 success\n",
    "with open(\"data/top_100_drivers.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_k_drivers(df, 100).collect()))\n",
    "    # top worst drivers - variant 2 success\n",
    "with open(\"data/worst_drivers.json\", \"w\") as f:\n",
    "  f.write(json.dumps(worst_drivers(df).collect()))\n",
    "    # dencent traffic by hour - variant 3 success\n",
    "with open(\"data/densest_traffic_by_hour.json\", \"w\") as f:\n",
    "  f.write(json.dumps(densest_traffic_by_hour(df).collect()))\n",
    "    # top 50 clients - variant 4 success\n",
    "with open(\"data/top_50_clients.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_k_clients(df, 50).collect()))\n",
    "    # top 50 night drivers - variant 6 - SUCCESS\n",
    "with open(\"data/top_night_riders.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_night_riders(df, 50).collect()))\n",
    "    # most frequent category of good drivers - variant 7 SUCCESS\n",
    "with open(\"data/top_praised_driver_category.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_driver_feedback_category(df).collect()))\n",
    "    # most frequent category of bad drivers - variant 8 SUCCESS\n",
    "with open(\"data/top_complaint_driver_category.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_complaint_feedback_category(df).collect()))\n",
    "    # top 10 longest text comments SUCCESS\n",
    "with open(\"data/top_10_longest_text_comments.json\", \"w\") as f:\n",
    "  f.write(json.dumps(top_10_longest_text_comment(df).collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "droqu7rCVllN"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
